{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polish-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "italian-quantity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset is: (36803, 228)\n",
      "The shape of the test dataset is: (15774, 227)\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('../../data/final_project/training.csv')\n",
    "test_data = pd.read_csv('../../data/final_project/public_test_features.csv')\n",
    "\n",
    "print('The shape of the training dataset is:', training_data.shape)\n",
    "print('The shape of the test dataset is:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "musical-moral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36803, 21) (15774, 20)\n"
     ]
    }
   ],
   "source": [
    "numerical_features = [\"key_pkg_height\",\"key_pkg_length\",\"key_pkg_width\",\"key_pkg_weight\",\n",
    "                              \"key_item_package_quantity\",\"key_fma_qualified_price_max\",\n",
    "                              \"cand_pkg_height\",\"cand_pkg_length\",\"cand_pkg_width\",\"cand_pkg_weight\",\n",
    "                              \"cand_item_package_quantity\",\"cand_fma_qualified_price_max\"]\n",
    "\n",
    "categorical_features = [\"key_classification_code\", \"key_Product Group Code\",\"key_color_map\",\n",
    "                        \"cand_classification_code\", \"cand_Product Group Code\",\"cand_color_map\"]\n",
    "\n",
    "text_features = [\"key_item_name\", \"cand_item_name\"]\n",
    "\n",
    "model_features = numerical_features + text_features + categorical_features\n",
    "labels = [\"label\"]\n",
    "\n",
    "df_train = training_data[labels + model_features]\n",
    "df_test = test_data[model_features]\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "limiting-contents",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>key_pkg_height</th>\n",
       "      <th>key_pkg_length</th>\n",
       "      <th>key_pkg_width</th>\n",
       "      <th>key_pkg_weight</th>\n",
       "      <th>key_item_package_quantity</th>\n",
       "      <th>key_fma_qualified_price_max</th>\n",
       "      <th>cand_pkg_height</th>\n",
       "      <th>cand_pkg_length</th>\n",
       "      <th>cand_pkg_width</th>\n",
       "      <th>...</th>\n",
       "      <th>cand_item_package_quantity</th>\n",
       "      <th>cand_fma_qualified_price_max</th>\n",
       "      <th>key_item_name</th>\n",
       "      <th>cand_item_name</th>\n",
       "      <th>key_classification_code</th>\n",
       "      <th>key_Product Group Code</th>\n",
       "      <th>key_color_map</th>\n",
       "      <th>cand_classification_code</th>\n",
       "      <th>cand_Product Group Code</th>\n",
       "      <th>cand_color_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.96</td>\n",
       "      <td>1.574803</td>\n",
       "      <td>18.110236</td>\n",
       "      <td>5.118110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.70</td>\n",
       "      <td>Nickelodeon Teenage Mutant Ninja Turtles You B...</td>\n",
       "      <td>Roommates Rmk2249Gm Teenage Mutant Ninja Turtl...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.71</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.41</td>\n",
       "      <td>BLOCKIT RFID Protector Sleeves - Made in the U...</td>\n",
       "      <td>RFID Blocking Sleeves (10 Credit Card &amp; 2 Pass...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.37</td>\n",
       "      <td>2.007874</td>\n",
       "      <td>5.236220</td>\n",
       "      <td>3.937008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.41</td>\n",
       "      <td>Dual Output Portable Charger, Oripow Spark A6 ...</td>\n",
       "      <td>Anker PowerCore 10000, One of the Smallest and...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>107</td>\n",
       "      <td>Black, Silver, Grey, Pink, Blue, Gold</td>\n",
       "      <td>base_product</td>\n",
       "      <td>107</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>648.63</td>\n",
       "      <td>2.401575</td>\n",
       "      <td>20.590551</td>\n",
       "      <td>10.314961</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.19</td>\n",
       "      <td>Optimus Popularis keyboard</td>\n",
       "      <td>Razer DeathStalker Expert - Backlit Ergonomic ...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>147</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.85</td>\n",
       "      <td>1.102362</td>\n",
       "      <td>7.874016</td>\n",
       "      <td>5.196850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.73</td>\n",
       "      <td>Zuke's Genuine Jerky Dog Treats, Beef and Carr...</td>\n",
       "      <td>Hill's Science Diet Beef Jerky Dog Treats, Jer...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>51.600000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>51.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1496.73</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>52.400000</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samsung UN55KS8000 55-Inch 4K Ultra HD Smart L...</td>\n",
       "      <td>LG Electronics 55\" LED TV (55SL5B-B)</td>\n",
       "      <td>base_product</td>\n",
       "      <td>504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>504</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.16</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.87</td>\n",
       "      <td>Ideashop 42mm Watch Replacement Wristband Sand...</td>\n",
       "      <td>MacTop Watch Band for Apple Watch Series 2 and...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>107</td>\n",
       "      <td>Dark brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.798972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246.79</td>\n",
       "      <td>1.732283</td>\n",
       "      <td>12.519685</td>\n",
       "      <td>1.811024</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.40</td>\n",
       "      <td>GoPro HERO3+: Silver Edition</td>\n",
       "      <td>Luxebell Selfie Stick Telescopic Pole Pocket P...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2.677165</td>\n",
       "      <td>6.377953</td>\n",
       "      <td>6.377953</td>\n",
       "      <td>1.410958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.10</td>\n",
       "      <td>1.692913</td>\n",
       "      <td>5.393701</td>\n",
       "      <td>4.015748</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.69</td>\n",
       "      <td>Apatite Rough Natural Stones 1 Lb (.5 Kg) Bulk...</td>\n",
       "      <td>20 (TWENTY) AAA Grade CHARGED 500 - 650cts BAB...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.76</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.70</td>\n",
       "      <td>PlanAhead Plan Ahead Agenda Book, Undated, 6.9...</td>\n",
       "      <td>Mead Pinstripe Weekly Wirebound Planner,  5-1/...</td>\n",
       "      <td>base_product</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>base_product</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  key_pkg_height  key_pkg_length  key_pkg_width  key_pkg_weight  \\\n",
       "0      0       10.000000       20.000000      15.000000        6.300000   \n",
       "1      0        0.200000        4.800000       4.000000        0.022046   \n",
       "2      1        2.100000        7.200000       4.600000        1.050000   \n",
       "3      1             NaN             NaN            NaN             NaN   \n",
       "4      1        0.200000        9.200000       7.500000        0.250000   \n",
       "5      1        6.500000       51.600000      31.500000       51.200000   \n",
       "6      0             NaN             NaN            NaN             NaN   \n",
       "7      1        3.800000       10.000000       4.000000        1.798972   \n",
       "8      1        2.677165        6.377953       6.377953        1.410958   \n",
       "9      0        0.800000        7.400000       7.000000        0.550000   \n",
       "\n",
       "   key_item_package_quantity  key_fma_qualified_price_max  cand_pkg_height  \\\n",
       "0                        1.0                       111.96         1.574803   \n",
       "1                        6.0                        15.71         0.300000   \n",
       "2                        1.0                        43.37         2.007874   \n",
       "3                        1.0                       648.63         2.401575   \n",
       "4                        1.0                        23.85         1.102362   \n",
       "5                        1.0                      1496.73         6.700000   \n",
       "6                        2.0                        42.16         0.300000   \n",
       "7                        1.0                       246.79         1.732283   \n",
       "8                        NaN                        21.10         1.692913   \n",
       "9                        1.0                        29.76         0.700000   \n",
       "\n",
       "   cand_pkg_length  cand_pkg_width  ...  cand_item_package_quantity  \\\n",
       "0        18.110236        5.118110  ...                         1.0   \n",
       "1         6.750000        4.500000  ...                         1.0   \n",
       "2         5.236220        3.937008  ...                         1.0   \n",
       "3        20.590551       10.314961  ...                         1.0   \n",
       "4         7.874016        5.196850  ...                         1.0   \n",
       "5        52.400000       31.800000  ...                         1.0   \n",
       "6         8.600000        2.200000  ...                         1.0   \n",
       "7        12.519685        1.811024  ...                         1.0   \n",
       "8         5.393701        4.015748  ...                        20.0   \n",
       "9         8.500000        5.500000  ...                         1.0   \n",
       "\n",
       "   cand_fma_qualified_price_max  \\\n",
       "0                         35.70   \n",
       "1                         19.41   \n",
       "2                         44.41   \n",
       "3                         95.19   \n",
       "4                         14.73   \n",
       "5                           NaN   \n",
       "6                         25.87   \n",
       "7                         20.40   \n",
       "8                         26.69   \n",
       "9                         18.70   \n",
       "\n",
       "                                       key_item_name  \\\n",
       "0  Nickelodeon Teenage Mutant Ninja Turtles You B...   \n",
       "1  BLOCKIT RFID Protector Sleeves - Made in the U...   \n",
       "2  Dual Output Portable Charger, Oripow Spark A6 ...   \n",
       "3                         Optimus Popularis keyboard   \n",
       "4  Zuke's Genuine Jerky Dog Treats, Beef and Carr...   \n",
       "5  Samsung UN55KS8000 55-Inch 4K Ultra HD Smart L...   \n",
       "6  Ideashop 42mm Watch Replacement Wristband Sand...   \n",
       "7                       GoPro HERO3+: Silver Edition   \n",
       "8  Apatite Rough Natural Stones 1 Lb (.5 Kg) Bulk...   \n",
       "9  PlanAhead Plan Ahead Agenda Book, Undated, 6.9...   \n",
       "\n",
       "                                      cand_item_name key_classification_code  \\\n",
       "0  Roommates Rmk2249Gm Teenage Mutant Ninja Turtl...            base_product   \n",
       "1  RFID Blocking Sleeves (10 Credit Card & 2 Pass...            base_product   \n",
       "2  Anker PowerCore 10000, One of the Smallest and...            base_product   \n",
       "3  Razer DeathStalker Expert - Backlit Ergonomic ...            base_product   \n",
       "4  Hill's Science Diet Beef Jerky Dog Treats, Jer...            base_product   \n",
       "5               LG Electronics 55\" LED TV (55SL5B-B)            base_product   \n",
       "6  MacTop Watch Band for Apple Watch Series 2 and...            base_product   \n",
       "7  Luxebell Selfie Stick Telescopic Pole Pocket P...            base_product   \n",
       "8  20 (TWENTY) AAA Grade CHARGED 500 - 650cts BAB...            base_product   \n",
       "9  Mead Pinstripe Weekly Wirebound Planner,  5-1/...            base_product   \n",
       "\n",
       "  key_Product Group Code                          key_color_map  \\\n",
       "0                    201                                    NaN   \n",
       "1                    229                                    NaN   \n",
       "2                    107  Black, Silver, Grey, Pink, Blue, Gold   \n",
       "3                    147                                    NaN   \n",
       "4                    199                                    NaN   \n",
       "5                    504                                    NaN   \n",
       "6                    107                                    NaN   \n",
       "7                    421                                    NaN   \n",
       "8                    201                                    NaN   \n",
       "9                    229                                    NaN   \n",
       "\n",
       "  cand_classification_code cand_Product Group Code  cand_color_map  \n",
       "0             base_product                      60             NaN  \n",
       "1             base_product                     107             NaN  \n",
       "2             base_product                     107           Black  \n",
       "3             base_product                     147             NaN  \n",
       "4             base_product                     199             NaN  \n",
       "5             base_product                     504             NaN  \n",
       "6             base_product                     107      Dark brown  \n",
       "7             base_product                     421             NaN  \n",
       "8             base_product                     201             NaN  \n",
       "9             base_product                     229             NaN  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-novel",
   "metadata": {},
   "source": [
    "## Cleaning Textual Features from train and test for use in neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "guided-upgrade",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train[categorical_features + text_features] = df_train[categorical_features + text_features].astype('str')\n",
    "df_test[categorical_features + text_features] = df_test[categorical_features + text_features].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "manufactured-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare cleaning functions\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preProcessText(text):\n",
    "    # lowercase and strip leading/trailing white space\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    \n",
    "    # remove extra white space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def lexiconProcess(text, stop_words, stemmer):\n",
    "    filtered_sentence = []\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "    text = \" \".join(filtered_sentence)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def cleanSentence(text, stop_words, stemmer):\n",
    "    return lexiconProcess(preProcessText(text), stop_words, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flush-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning:  key_item_name\n",
      "Text cleaning:  cand_item_name\n"
     ]
    }
   ],
   "source": [
    "# Clean the text features\n",
    "for c in text_features:\n",
    "    print('Text cleaning: ', c)\n",
    "    df_train[c] = [cleanSentence(item, stop_words, stemmer) for item in df_train[c].values]\n",
    "    df_test[c] = [cleanSentence(item, stop_words, stemmer) for item in df_test[c].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "creative-scratch",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_item_name\n",
      "['nickelodeon teenag mutant ninja turtl charact twin bed bag bed set'\n",
      " 'blockit rfid protector sleev made usa recommend lifelock 6 pack credit debit card protector slim card holder fit men women wallet includ bonus secur ebook'\n",
      " 'dual output portabl charger oripow spark a6 19200mah extern batteri batteri pack iphon ipad samsung htc nexus phone tablet 5v digit devic grey '\n",
      " ... 'canon eo rebel t6i digit slr ef 18 55mm stm len wi fi enabl'\n",
      " 'militari invas star circl decal 22 inch hood decal restor custom armi willi truck jeep cj wrangler flat matt black'\n",
      " 'tactic polic heavi duti 3w recharg flashlight']\n",
      "cand_item_name\n",
      "['roommat rmk2249gm teenag mutant ninja turtl leo peel stick giant wall decal'\n",
      " 'rfid block sleev 10 credit card 2 passport protector 01 digit secur ident theft protect travel case set smart holder fit wallet purs cell phone'\n",
      " 'anker powercor 10000 one smallest lightest 10000mah extern batteri ultra compact high speed charg technolog power bank iphon samsung galaxi'\n",
      " ... 'amscop kid 40x 1000x dual illumin microscop red slide prep kit book'\n",
      " 't3 featherweight lux 2i dryer'\n",
      " 'green valley organ sweet pea 15 ounc pack 12 ']\n"
     ]
    }
   ],
   "source": [
    "for c in text_features:\n",
    "    print(c)\n",
    "    print(df_train[c].unique()) #value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-brazil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for c in [\"key_color_map\",\"cand_color_map\"]:\n",
    "#     print('Text Cleaning: ', c)\n",
    "#     df_train[c] = [cleanSentence(item, stop_words, stemmer) for item in df_train[c].values]\n",
    "#     df_test[c] = [cleanSentence(item, stop_words, stemmer) for item in df_test[c].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in [\"key_color_map\",\"cand_color_map\"]:\n",
    "#     print(c)\n",
    "#     print(df_train[c].unique()) #value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-hypothesis",
   "metadata": {},
   "source": [
    "## Splitting the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fatty-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(df_train\n",
    "                                               ,test_size=0.10, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instrumental-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33122, 21) (3681, 21)\n",
      "1811\n",
      "1870\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, val_data.shape)\n",
    "\n",
    "print(sum(val_data[\"label\"] == 0))\n",
    "print(sum(val_data[\"label\"] == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-associate",
   "metadata": {},
   "source": [
    "## Defining the pipeline for the imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "certain-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### COLUMN_TRANSFORMER ###\n",
    "##########################\n",
    "\n",
    "# Preprocess the numerical features\n",
    "numerical_processor = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('num_scaler', MinMaxScaler())\n",
    "                                ])\n",
    "                  \n",
    "# Preprocess the categorical features\n",
    "categorical_processor = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant', fill_value='missing')), # Shown in case is needed, no effect here as we already imputed with 'nan' strings\n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore')) # handle_unknown tells it to ignore (rather than throw an error for) any value that was not present in the initial training set.\n",
    "                                ])\n",
    "\n",
    "# Preprocess 1st text feature\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vectorizer_0', TfidfVectorizer(max_features=250))\n",
    "                                ])\n",
    "\n",
    "# Preprocess 2nd text feature (larger vocabulary)\n",
    "text_processor_1 = Pipeline([\n",
    "    ('text_vectorizer_1', TfidfVectorizer(max_features=250))\n",
    "                                ])\n",
    "# Combine all data preprocessors from above (add more, if you choose to define more!)\n",
    "# For each processor/step specify: a name, the actual process, and finally the features to be processed\n",
    "data_processor = ColumnTransformer([\n",
    "    ('numerical_processing', numerical_processor, numerical_features),\n",
    "    ('categorical_processing', categorical_processor, categorical_features),\n",
    "    ('text_processing_0', text_processor_0, text_features[0]),\n",
    "    ('text_processing_1', text_processor_1, text_features[1])\n",
    "                                    ]\n",
    "        ,remainder='passthrough')\n",
    "\n",
    "# Visualize the data processing pipeline\n",
    "#from sklearn import set_config\n",
    "#sklearn.set_config(display='diagram')\n",
    "#data_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "furnished-concentration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets shapes before processing:  (33122, 20) (3681, 20) (15774, 20)\n",
      "Datasets shapes after processing:  (33122, 1271) (3681, 1271) (15774, 1271)\n"
     ]
    }
   ],
   "source": [
    "### DATA PROCESSING ###\n",
    "#######################\n",
    "# Get train data to pass through the imputer\n",
    "X_train = train_data[model_features]\n",
    "y_train = train_data[labels]\n",
    "\n",
    "# Get val data to pass through the imputer\n",
    "X_val = val_data[model_features]\n",
    "y_val = val_data[labels]\n",
    "\n",
    "#Get test data to pass through the imputer\n",
    "X_test = df_test\n",
    "\n",
    "print('Datasets shapes before processing: ', X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "X_train = data_processor.fit_transform(X_train)\n",
    "X_val = data_processor.transform(X_val)\n",
    "X_test = data_processor.transform(X_test)\n",
    "\n",
    "X_train=X_train.astype('float32').todense()\n",
    "X_val=X_val.astype('float32').todense()\n",
    "X_test=X_test.astype('float32').todense()\n",
    "\n",
    "print('Datasets shapes after processing: ', X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating features from categorical and dimensional features for train dataset\n",
    "# df_model[\"difference_pkg_weight\"] = pd.Series(np.absolute(df_model[\"key_pkg_weight\"] - df_model[\"cand_pkg_weight\"]))\n",
    "\n",
    "# # df_model[\"same_binding_code\"] = pd.Series(np.where((df_model[\"key_Binding Code\"] == \n",
    "# #                                                             df_model[\"cand_Binding Code\"]), 1, 0))\n",
    "# # df_model[\"same_product_type\"] = pd.Series(np.where((df_model[\"key_product_type\"] == \n",
    "# #                                                             df_model[\"cand_product_type\"]), 1, 0))\n",
    "\n",
    "# df_model[\"same_classification_code\"] = pd.Series(np.where((df_model[\"key_classification_code\"] ==\n",
    "#                                                         df_model[\"cand_classification_code\"]), 1, 0))\n",
    "# df_model[\"same_group_description\"] = pd.Series(np.where((df_model[\"key_Product Group Description\"] ==\n",
    "#                                                         df_model[\"cand_Product Group Description\"]), 1, 0))\n",
    "# df_model[\"same_color_map\"] = pd.Series(np.where((df_model[\"key_color_map\"] ==\n",
    "#                                                         df_model[\"cand_color_map\"]), 1, 0))\n",
    "\n",
    "# #creating features from categorical and dimensional features for test dataset\n",
    "# test_data[\"difference_pkg_weight\"] = pd.Series(np.absolute(df_model[\"key_pkg_weight\"] - df_model[\"cand_pkg_weight\"]))\n",
    "\n",
    "# # test_data[\"same_binding_code\"] = pd.Series(np.where((test_data[\"key_Binding Code\"] == \n",
    "# #                                                             test_data[\"cand_Binding Code\"]), 1, 0))\n",
    "# # test_data[\"same_product_type\"] = pd.Series(np.where((test_data[\"key_product_type\"] == \n",
    "# #                                                             test_data[\"cand_product_type\"]), 1, 0))\n",
    "# test_data[\"same_classification_code\"] = pd.Series(np.where((test_data[\"key_classification_code\"] ==\n",
    "#                                                         test_data[\"cand_classification_code\"]), 1, 0))\n",
    "# test_data[\"same_group_description\"] = pd.Series(np.where((test_data[\"key_Product Group Description\"] ==\n",
    "#                                                         test_data[\"cand_Product Group Description\"]), 1, 0))\n",
    "# test_data[\"same_color_map\"] = pd.Series(np.where((test_data[\"key_color_map\"] ==\n",
    "#                                                         test_data[\"cand_color_map\"]), 1, 0))\n",
    "\n",
    "# print(df_model.shape, test_data.shape)\n",
    "# print(train_features)\n",
    "\n",
    "# #adding created features to the train_feature set and setting the list of features to be used for the model\n",
    "# categorical_features = [\"same_pkg_weight\",\"same_classification_code\",\"same_group_description\",\"same_color_map\"]\n",
    "# dimension_related_features = [i for i in dimension_related_features if i not in [\"key_pkg_weight\",\"cand_pkg_weight\"]]\n",
    "\n",
    "# train_features = dimension_related_features + categorical_features + text_features\n",
    "\n",
    "# df_model = df_model[labels + train_features]\n",
    "# df_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-prior",
   "metadata": {},
   "source": [
    "## Model Training Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "female-little",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 0.69, validation loss: 0.69,     training accuracy: 0.52, validation accuracy: 0.54\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.70      0.60      1811\n",
      "           1       0.57      0.39      0.46      1870\n",
      "\n",
      "    accuracy                           0.54      3681\n",
      "   macro avg       0.55      0.54      0.53      3681\n",
      "weighted avg       0.55      0.54      0.53      3681\n",
      "\n",
      "Epoch 1, training loss: 0.69, validation loss: 0.69,     training accuracy: 0.54, validation accuracy: 0.55\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.66      0.59      1811\n",
      "           1       0.57      0.44      0.49      1870\n",
      "\n",
      "    accuracy                           0.55      3681\n",
      "   macro avg       0.55      0.55      0.54      3681\n",
      "weighted avg       0.55      0.55      0.54      3681\n",
      "\n",
      "Epoch 2, training loss: 0.69, validation loss: 0.68,     training accuracy: 0.55, validation accuracy: 0.56\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.65      0.59      1811\n",
      "           1       0.58      0.47      0.52      1870\n",
      "\n",
      "    accuracy                           0.56      3681\n",
      "   macro avg       0.56      0.56      0.55      3681\n",
      "weighted avg       0.56      0.56      0.55      3681\n",
      "\n",
      "Epoch 3, training loss: 0.68, validation loss: 0.68,     training accuracy: 0.56, validation accuracy: 0.56\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60      1811\n",
      "           1       0.59      0.46      0.52      1870\n",
      "\n",
      "    accuracy                           0.56      3681\n",
      "   macro avg       0.57      0.57      0.56      3681\n",
      "weighted avg       0.57      0.56      0.56      3681\n",
      "\n",
      "Epoch 4, training loss: 0.68, validation loss: 0.68,     training accuracy: 0.56, validation accuracy: 0.57\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61      1811\n",
      "           1       0.60      0.47      0.53      1870\n",
      "\n",
      "    accuracy                           0.57      3681\n",
      "   macro avg       0.58      0.57      0.57      3681\n",
      "weighted avg       0.58      0.57      0.57      3681\n",
      "\n",
      "Epoch 5, training loss: 0.68, validation loss: 0.68,     training accuracy: 0.57, validation accuracy: 0.58\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.68      0.61      1811\n",
      "           1       0.61      0.48      0.53      1870\n",
      "\n",
      "    accuracy                           0.58      3681\n",
      "   macro avg       0.58      0.58      0.57      3681\n",
      "weighted avg       0.58      0.58      0.57      3681\n",
      "\n",
      "Epoch 6, training loss: 0.67, validation loss: 0.67,     training accuracy: 0.58, validation accuracy: 0.59\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62      1811\n",
      "           1       0.62      0.50      0.56      1870\n",
      "\n",
      "    accuracy                           0.59      3681\n",
      "   macro avg       0.60      0.59      0.59      3681\n",
      "weighted avg       0.60      0.59      0.59      3681\n",
      "\n",
      "Epoch 7, training loss: 0.67, validation loss: 0.67,     training accuracy: 0.59, validation accuracy: 0.60\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62      1811\n",
      "           1       0.62      0.55      0.58      1870\n",
      "\n",
      "    accuracy                           0.60      3681\n",
      "   macro avg       0.60      0.60      0.60      3681\n",
      "weighted avg       0.60      0.60      0.60      3681\n",
      "\n",
      "Epoch 8, training loss: 0.67, validation loss: 0.67,     training accuracy: 0.59, validation accuracy: 0.60\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63      1811\n",
      "           1       0.63      0.53      0.58      1870\n",
      "\n",
      "    accuracy                           0.60      3681\n",
      "   macro avg       0.61      0.61      0.60      3681\n",
      "weighted avg       0.61      0.60      0.60      3681\n",
      "\n",
      "Epoch 9, training loss: 0.66, validation loss: 0.66,     training accuracy: 0.60, validation accuracy: 0.61\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63      1811\n",
      "           1       0.64      0.56      0.59      1870\n",
      "\n",
      "    accuracy                           0.61      3681\n",
      "   macro avg       0.62      0.61      0.61      3681\n",
      "weighted avg       0.62      0.61      0.61      3681\n",
      "\n",
      "Epoch 10, training loss: 0.66, validation loss: 0.66,     training accuracy: 0.61, validation accuracy: 0.61\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.67      0.63      1811\n",
      "           1       0.64      0.55      0.59      1870\n",
      "\n",
      "    accuracy                           0.61      3681\n",
      "   macro avg       0.61      0.61      0.61      3681\n",
      "weighted avg       0.61      0.61      0.61      3681\n",
      "\n",
      "Epoch 11, training loss: 0.65, validation loss: 0.65,     training accuracy: 0.62, validation accuracy: 0.62\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62      1811\n",
      "           1       0.63      0.58      0.61      1870\n",
      "\n",
      "    accuracy                           0.62      3681\n",
      "   macro avg       0.62      0.62      0.62      3681\n",
      "weighted avg       0.62      0.62      0.62      3681\n",
      "\n",
      "Epoch 12, training loss: 0.65, validation loss: 0.65,     training accuracy: 0.62, validation accuracy: 0.62\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62      1811\n",
      "           1       0.63      0.63      0.63      1870\n",
      "\n",
      "    accuracy                           0.62      3681\n",
      "   macro avg       0.62      0.62      0.62      3681\n",
      "weighted avg       0.62      0.62      0.62      3681\n",
      "\n",
      "Epoch 13, training loss: 0.65, validation loss: 0.65,     training accuracy: 0.63, validation accuracy: 0.62\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63      1811\n",
      "           1       0.64      0.59      0.62      1870\n",
      "\n",
      "    accuracy                           0.62      3681\n",
      "   macro avg       0.63      0.62      0.62      3681\n",
      "weighted avg       0.63      0.62      0.62      3681\n",
      "\n",
      "Epoch 14, training loss: 0.64, validation loss: 0.65,     training accuracy: 0.63, validation accuracy: 0.63\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62      1811\n",
      "           1       0.63      0.65      0.64      1870\n",
      "\n",
      "    accuracy                           0.63      3681\n",
      "   macro avg       0.63      0.63      0.63      3681\n",
      "weighted avg       0.63      0.63      0.63      3681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Import the necessary libraries and classes\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import mxnet.ndarray as nd\n",
    "import numpy as np\n",
    "\n",
    "# Using CPU resource; mx.gpu() will use GPU resources if available\n",
    "ctx = mx.cpu()   \n",
    "\n",
    "\n",
    "######################\n",
    "# Use Gluon Data Loaders to load the data in batches, while also converting to ND arrays for Gluon\n",
    "train_dataset = mx.gluon.data.dataset.ArrayDataset(nd.array(X_train), nd.array(y_train))\n",
    "val_dataset = mx.gluon.data.dataset.ArrayDataset(nd.array(X_val), nd.array(y_val))\n",
    "\n",
    "train_data_loader = mx.gluon.data.DataLoader(train_dataset, batch_size=16)\n",
    "val_data_loader = mx.gluon.data.DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "######################\n",
    "# Create a simple MultiLayer Perceptron using the Sequential mode - add things in sequence\n",
    "#  with two hidden layers of size 64 and 128 \n",
    "#  some dropouts attached to the hidden layers\n",
    "#  one output layer\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(128 ,activation='relu'),    # Layer 1\n",
    "        nn.Dropout(.4),                     # Apply random 40% dropout to layer 1\n",
    "        nn.Dense(256, activation='relu'),   # Layer 2\n",
    "        nn.Dropout(.3),                     # Apply random 30% dropout to layer 2\n",
    "        nn.Dense(1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# print(net)     # print the network\n",
    "# print(net[0])  # access individual layers\n",
    "\n",
    "\n",
    "######################\n",
    "# Initialize the weights parameters of the network with the Xavier initialization\n",
    "#  Weights are actually initialized when passing input data through network, when network input size is learned from the input data.\n",
    "from mxnet import init\n",
    "net.collect_params().initialize(mx.init.Xavier())\n",
    "\n",
    "######################\n",
    "# Hyper-paramaters of the system\n",
    "batch_size = 18\n",
    "epochs = 15\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "######################\n",
    "# Define the loss function and the trainer\n",
    "from mxnet.gluon.loss import SigmoidBinaryCrossEntropyLoss\n",
    "\n",
    "# Choose SigmoidBinaryCrossEntropyLoss for this binary classification problem\n",
    "#  https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/gluon/loss/index.html#mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss\n",
    "binary_cross_entropy_loss = SigmoidBinaryCrossEntropyLoss(from_sigmoid=True)\n",
    "\n",
    "# Choose Stochastic Gradient Descent - can also experiment with other optimizers\n",
    "#  https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/optimizer/index.html#\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': learning_rate})\n",
    "\n",
    "\n",
    "######################\n",
    "# Network Training and Validation\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from mxnet import autograd # autograd package expedites gradient calculations\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Starting the outer epoch loop (epoch = full pass through our dataset)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Training loop: (with autograd and trainer steps)\n",
    "    # This loop does the training of the neural network\n",
    "    # Weights are updated here\n",
    "    cumulative_train_loss = 0\n",
    "    train_predictions = []\n",
    "    for i, (data, label) in enumerate(train_data_loader):\n",
    "        with autograd.record():\n",
    "            # Forward Pass input data through the network to make predictions\n",
    "            output = net(data) \n",
    "            train_predictions += np.squeeze(output.asnumpy()).tolist()\n",
    "        \n",
    "            # Calculate the loss and add it to the cumulative loss\n",
    "            loss = binary_cross_entropy_loss(output, label)\n",
    "            cumulative_train_loss = cumulative_train_loss + nd.sum(loss)\n",
    "            \n",
    "            # Invoke Backpropagation (backprop) by calling loss.backward()\n",
    "            loss.backward()\n",
    "            \n",
    "        trainer.step(data.shape[0])\n",
    "\n",
    "    # Calculating the Log-loss for training data\n",
    "    train_loss = cumulative_train_loss/len(X_train)\n",
    "    train_losses.append(train_loss.asnumpy()[0])\n",
    "\n",
    "\n",
    "    # Validation loop:\n",
    "    # This loop validates the trained network on validation dataset\n",
    "    # No weight updates here    \n",
    "    cumulative_val_loss = 0\n",
    "    val_predictions = []\n",
    "    for i, (data, label) in enumerate(val_data_loader):\n",
    "        # Forward Pass validation data through the network to make predictions\n",
    "        output = net(data) \n",
    "        try:\n",
    "            val_predictions += np.squeeze(output.asnumpy()).tolist()\n",
    "        except:\n",
    "            val_predictions.append(np.squeeze(output.asnumpy()).tolist())\n",
    "        \n",
    "        # Calculate the loss and add it to the cumulative loss\n",
    "        val_loss = binary_cross_entropy_loss(output, label)\n",
    "        cumulative_val_loss = cumulative_val_loss + nd.sum(val_loss)\n",
    "    \n",
    "    # Calculating the Log-loss for validation data\n",
    "    val_loss = cumulative_val_loss/len(X_val)\n",
    "    val_losses.append(val_loss.asnumpy()[0])\n",
    "    \n",
    "    \n",
    "    # Round predictions: 0.5 and up becomes 1, 0 otherwise\n",
    "    train_predictions = [round(train_pred) for train_pred in train_predictions]\n",
    "    val_predictions = [round(val_pred) for val_pred in val_predictions]\n",
    "\n",
    "    # Calculate training and validation accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    validation_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    validation_report = classification_report(y_val, val_predictions)\n",
    "    \n",
    "    print(\"Epoch {}, training loss: {:.2f}, validation loss: {:.2f}, \\\n",
    "    training accuracy: {:.2f}, validation accuracy: {:.2f}\".format(epoch, \\\n",
    "                                                                   train_loss.asnumpy()[0], \n",
    "                                                                   val_loss.asnumpy()[0], \n",
    "                                                                   train_accuracy, \n",
    "                                                                   validation_accuracy))\n",
    "    print(\"Classification report \\n\", validation_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tired-singapore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.title(\"Loss values\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "enabling-academy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15774"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the network on the test data\n",
    "test_input = nd.array(X_test.astype('float32')).as_in_context(ctx)\n",
    "test_predictions_0 = net(test_input)\n",
    "\n",
    "# Round predictions: 0.5 and up becomes 1, 0 otherwise\n",
    "test_predictions = [round(pred) for pred in np.squeeze(test_predictions_0.asnumpy()).tolist()]\n",
    "\n",
    "len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "final-protocol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  label\n",
       "0  35057      1\n",
       "1  41573      0\n",
       "2  44029      0\n",
       "3   6462      1\n",
       "4  17533      0\n",
       "5  22432      0\n",
       "6  37471      0\n",
       "7  26858      0\n",
       "8  37282      1\n",
       "9  21448      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"label\"] = test_predictions\n",
    "submission = test_data[[\"ID\",\"label\"]]\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "separate-distinction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8015\n",
       "0    7759\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "demanding-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../../data/final_project/NN_V_4.0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-boulder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
